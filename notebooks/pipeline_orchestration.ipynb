{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Price Optimization Pipeline Orchestration\n",
    "\n",
    "This notebook allows you to run the training and inference pipelines interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add project root to path so we can import modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from pipelines.deployment_pipeline import deployment_pipeline\n",
    "from pipelines.inference_pipeline import inference_pipeline\n",
    "from constants import MODEL_NAME, PIPELINE_NAME, PIPELINE_STEP_NAME\n",
    "from zenml.config import DockerSettings\n",
    "from zenml.integrations.constants import MLFLOW\n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Ensure your `.env` file is set up with `DB_URL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join('..', '.env'))\n",
    "\n",
    "print(f\"Using DB_URL: {os.getenv('DB_URL')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Deployment Pipeline\n",
    "This pipeline ingests data, trains the model, and deploys it if accuracy is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run just the ingest_data step to see the actual error\n",
    "try:\n",
    "    deployment_pipeline(\n",
    "        min_accuracy=0.5,\n",
    "        workers=3,\n",
    "        timeout=60\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Full error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MLflow\n",
    "View the MLflow tracking URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MLflow tracking URI: {get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference Pipeline\n",
    "This pipeline loads the deployed model and runs inference on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from zenml.pipelines import pipeline\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "PIPELINE_NAME = \"your_pipeline_name\"\n",
    "PIPELINE_STEP_NAME = \"your_step_name\"\n",
    "\n",
    "# Try-catch wrapper with detailed error reporting\n",
    "try:\n",
    "    inference_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_step_name=PIPELINE_STEP_NAME,\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    logger.error(f\"Pipeline execution failed: {e}\")\n",
    "    logger.error(\"Failed steps detected. Debugging information:\")\n",
    "    \n",
    "    # Get detailed error info\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Common issues to check:\n",
    "    print(\"\\n=== DEBUGGING CHECKLIST ===\")\n",
    "    print(\"1. Check if ingest_data_for_inference step has correct file paths\")\n",
    "    print(\"2. Verify prediction_service_loader can find the model file\")\n",
    "    print(\"3. Ensure all required dependencies are installed\")\n",
    "    print(\"4. Check file permissions and disk space\")\n",
    "    print(\"5. Verify data format matches expected schema\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Unexpected error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "\n",
    "# ===== COMMON FIXES =====\n",
    "\n",
    "# Fix 1: Add step-level error handling\n",
    "@pipeline(name=\"inference_pipeline_v2\")\n",
    "def inference_pipeline_with_error_handling(\n",
    "    pipeline_name: str,\n",
    "    pipeline_step_name: str,\n",
    "):\n",
    "    \"\"\"Inference pipeline with improved error handling.\"\"\"\n",
    "    try:\n",
    "        # Load data step\n",
    "        data = ingest_data_for_inference(pipeline_name=pipeline_name)\n",
    "        \n",
    "        # Load prediction service\n",
    "        model = prediction_service_loader(pipeline_name=pipeline_name)\n",
    "        \n",
    "        return model, data\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Step failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Fix 2: Add data validation\n",
    "def validate_input_data(data):\n",
    "    \"\"\"Validate input data format and schema.\"\"\"\n",
    "    if data is None:\n",
    "        raise ValueError(\"Input data is None\")\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"Input data is empty\")\n",
    "    logger.info(f\"Data validation passed. Shape: {data.shape if hasattr(data, 'shape') else len(data)}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# Fix 3: Add model validation\n",
    "def validate_model(model):\n",
    "    \"\"\"Validate loaded model.\"\"\"\n",
    "    if model is None:\n",
    "        raise ValueError(\"Model failed to load\")\n",
    "    logger.info(\"Model validation passed\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLOps)",
   "language": "python",
   "name": "mlops_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
